{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this challenge, you will need to choose a corpus of data from nltk or another source that includes categories you can predict and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "1. Data cleaning / processing / language parsing\n",
    "2. Create features using two different NLP methods: For example, BoW vs tf-idf.\n",
    "3. Use the features to fit supervised learning models for each feature set to predict the category outcomes.\n",
    "4. Assess your models using cross-validation and determine whether one model performed better.\n",
    "5. Pick one of the models and try to increase accuracy by at least 5 percentage points.\n",
    "\n",
    "Write up your report in a Jupyter notebook. Be sure to explicitly justify the choices you make throughout, and submit it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/nickdelucchi/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     /Users/nickdelucchi/nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "nltk.download('punkt')\n",
    "nltk.download('gutenberg')\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedShuffleSplit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "print(gutenberg.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ Paradise Lost by John Milton 1667 ]', 'Book I', \"Of Man ' s first disobedience , and the fruit Of that forbidden tree whose mortal taste Brought death into the World , and all our woe , With loss of Eden , till one greater Man Restore us , and regain the blissful seat , Sing , Heavenly Muse , that , on the secret top Of Oreb , or of Sinai , didst inspire That shepherd who first taught the chosen seed In the beginning how the heavens and earth Rose out of Chaos : or , if Sion hill Delight thee more , and Siloa ' s brook that flowed Fast by the oracle of God , I thence Invoke thy aid to my adventurous song , That with no middle flight intends to soar Above th ' Aonian mount , while it pursues Things unattempted yet in prose or rhyme .\", 'Book II', 'High on a throne of royal state , which far Outshone the wealth or Ormus and of Ind , Or where the gorgeous East with richest hand Showers on her kings barbaric pearl and gold , Satan exalted sat , by merit raised To that bad eminence ; and , from despair Thus high uplifted beyond hope , aspires Beyond thus high , insatiate to pursue Vain war with Heaven ; and , by success untaught , His proud imaginations thus displayed : \" Powers and Dominions , Deities of Heaven ! For , since no deep within her gulf can hold Immortal vigour , though oppressed and fallen , I give not Heaven for lost : from this descent Celestial Virtues rising will appear More glorious and more dread than from no fall , And trust themselves to fear no second fate ! Me though just right , and the fixed laws of Heaven , Did first create your leader  next , free choice With what besides in council or in fight Hath been achieved of merit  yet this loss , Thus far at least recovered , hath much more Established in a safe , unenvied throne , Yielded with full consent .', 'Book III', \"Hail , holy Light , offspring of Heaven firstborn , Or of the Eternal coeternal beam May I express thee unblam ' d ?\", \"00021053 Thou , therefore , whom thou only canst redeem , Their nature also to thy nature join ; And be thyself Man among men on Earth , Made flesh , when time shall be , of virgin seed , By wondrous birth ; be thou in Adam ' s room The head of all mankind , though Adam ' s son .\", 'Book IV', 'O , for that warning voice , which he , who saw The Apocalypse , heard cry in Heaven aloud , Then when the Dragon , put to second rout , Came furious down to be revenged on men , Woe to the inhabitants on earth !']\n"
     ]
    }
   ],
   "source": [
    "#reading in the data, this time in the form of paragraphs\n",
    "paradise = gutenberg.paras('milton-paradise.txt')\n",
    "#processing\n",
    "\n",
    "paradise_paras=[]\n",
    "for paragraph in paradise:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    paradise_paras.append(' '.join(para))\n",
    "\n",
    "print(paradise_paras[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[ Poems by William Blake 1789 ]', 'SONGS OF INNOCENCE AND OF EXPERIENCE and THE BOOK of THEL', 'SONGS OF INNOCENCE', 'INTRODUCTION', 'Piping down the valleys wild , Piping songs of pleasant glee , On a cloud I saw a child , And he laughing said to me :', '\" Pipe a song about a Lamb !\"', '\" Drop thy pipe , thy happy pipe ; Sing thy songs of happy cheer :!\"', '\" Piper , sit thee down and write In a book , that all may read .\"', \"And I made a rural pen , And I stain ' d the water clear , And I wrote my happy songs Every child may joy to hear .\", 'THE SHEPHERD']\n"
     ]
    }
   ],
   "source": [
    "#reading in the data, this time in the form of paragraphs\n",
    "blake = gutenberg.paras('blake-poems.txt')\n",
    "#processing\n",
    "\n",
    "blake_paras=[]\n",
    "for paragraph in blake:\n",
    "    para=paragraph[0]\n",
    "    #removing the double-dash from all words\n",
    "    para=[re.sub(r'--','',word) for word in para]\n",
    "    #Forming each paragraph into a string and adding it to the list of strings.\n",
    "    blake_paras.append(' '.join(para))\n",
    "\n",
    "print(blake_paras[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ Paradise Lost by John Milton 1667 ]</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book I</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Of Man ' s first disobedience , and the fruit ...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Book II</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>High on a throne of royal state , which far Ou...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1\n",
       "0              [ Paradise Lost by John Milton 1667 ]  Milton\n",
       "1                                             Book I  Milton\n",
       "2  Of Man ' s first disobedience , and the fruit ...  Milton\n",
       "3                                            Book II  Milton\n",
       "4  High on a throne of royal state , which far Ou...  Milton"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "paradiseparas = [[para, \"Milton\"] for para in paradise_paras]\n",
    "blakeparas = [[para, \"Blake\"] for para in blake_paras]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "paras = pd.DataFrame(paradiseparas + blakeparas)\n",
    "paras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 466\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(paras.drop(1,axis=1),paras[1], test_size=0.4, random_state=0)\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=2, # only use words that appear at least twice\n",
    "                             stop_words='english', \n",
    "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "\n",
    "#Applying the vectorizer\n",
    "paras_tfidf=vectorizer.fit_transform(paras.drop(1,axis=1)[0].tolist())\n",
    "print(\"Number of features: %d\" % paras_tfidf.get_shape()[1])\n",
    "\n",
    "#splitting into training and test sets\n",
    "X_train_tfidf, X_test_tfidf= train_test_split(paras_tfidf, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "#Reshapes the vectorizer output into something people can read\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "X_test_tfidf_csr = X_test_tfidf.tocsr()\n",
    "\n",
    "#number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "#A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "#List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "#for each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.0\n",
      "\n",
      "Test set score: 0.9603174603174603\n",
      "\n",
      "Cross Validation:\n",
      "    0.95 (+/- 0.04)\n",
      "[0.92307692 1.         0.92307692 0.92307692 1.         1.\n",
      " 1.         0.92307692 0.92307692 0.92307692]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "\n",
    "rfc.fit(X_train_tfidf_csr, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train_tfidf_csr, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test_tfidf_csr, y_test))\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, random_state=1337)\n",
    "\n",
    "score = cross_val_score(rfc, X_test_tfidf_csr, y_test, cv=split, scoring='accuracy')\n",
    "print(\"\\nCross Validation:\\n    %0.2f (+/- %0.2f)\" % (score.mean(), score.std()))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9090909090909091\n",
      "\n",
      "Test set score: 0.9047619047619048\n",
      "\n",
      "Cross Validation:\n",
      "    0.96 (+/- 0.04)\n",
      "[1.         1.         0.92307692 0.92307692 1.         1.\n",
      " 1.         0.92307692 0.92307692 0.92307692]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "lr.fit(X_train_tfidf_csr, y_train)\n",
    "\n",
    "print('Training set score:', lr.score(X_train_tfidf_csr, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test_tfidf_csr, y_test))\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, random_state=1337)\n",
    "\n",
    "score = cross_val_score(lr, X_test_tfidf_csr, y_test, cv=split, scoring='accuracy')\n",
    "print(\"\\nCross Validation:\\n    %0.2f (+/- %0.2f)\" % (score.mean(), score.std()))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.0\n",
      "\n",
      "Test set score: 0.9603174603174603\n",
      "\n",
      "Cross Validation:\n",
      "    0.96 (+/- 0.04)\n",
      "[1.         1.         0.92307692 0.92307692 1.         1.\n",
      " 1.         0.92307692 0.92307692 0.92307692]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "train = clf.fit(X_train_tfidf_csr, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train_tfidf_csr, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test_tfidf_csr, y_test))\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, random_state=1337)\n",
    "\n",
    "score = cross_val_score(lr, X_test_tfidf_csr, y_test, cv=split, scoring='accuracy')\n",
    "print(\"\\nCross Validation:\\n    %0.2f (+/- %0.2f)\" % (score.mean(), score.std()))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Of Man's first disobedience, and the fruit Of that forbidden tree whose mortal taste Brought death i\n",
      "Piping down the valleys wild, Piping songs of pleasant glee, On a cloud saw a child, And he laughing\n"
     ]
    }
   ],
   "source": [
    "# Utility function for standard text cleaning.\n",
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "    \n",
    "# Load and clean the data.\n",
    "#macbeth = gutenberg.raw('shakespeare-macbeth.txt')\n",
    "paradise = gutenberg.raw('milton-paradise.txt')\n",
    "blake = gutenberg.raw('blake-poems.txt')\n",
    "\n",
    "# unique cleaning\n",
    "paradise = re.sub(r'Book \\D{1,3}', '', paradise)\n",
    "blake = re.sub(r\"[A-Z]+\\b\",\"\",blake)\n",
    "blake = re.sub(r\"and   of\",\"\",blake)\n",
    "\n",
    "paradise = text_cleaner(paradise[:int(len(paradise)/10)])\n",
    "blake = text_cleaner(blake[:int(len(blake)/10)])\n",
    "\n",
    "print(paradise[:100])\n",
    "print(blake[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the cleaned novels. This can take a bit.\n",
    "nlp = spacy.load('en')\n",
    "paradise_doc = nlp(paradise)\n",
    "blake_doc = nlp(blake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(Of, Man, 's, first, disobedience, ,, and, the...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(And, chiefly, thou, ,, O, Spirit, ,, that, do...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Say, first, for, Heaven, hides, nothing, from...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Who, first, seduced, them, to, that, foul, re...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(Th, ', infernal, Serpent, ;, he, it, was, who...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0       1\n",
       "0  (Of, Man, 's, first, disobedience, ,, and, the...  Milton\n",
       "1  (And, chiefly, thou, ,, O, Spirit, ,, that, do...  Milton\n",
       "2  (Say, first, for, Heaven, hides, nothing, from...  Milton\n",
       "3  (Who, first, seduced, them, to, that, foul, re...  Milton\n",
       "4  (Th, ', infernal, Serpent, ;, he, it, was, who...  Milton"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group into sentences.\n",
    "paradise_sents = [[sent, \"Milton\"] for sent in paradise_doc.sents]\n",
    "blake_sents = [[sent, \"Blake\"] for sent in blake_doc.sents]\n",
    "\n",
    "# Combine the sentences from the two novels into one data frame.\n",
    "sentences = pd.DataFrame(paradise_sents + blake_sents)\n",
    "sentences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to create a list of the 2000 most common words.\n",
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]\n",
    "\n",
    "# Creates a data frame with features for each word in our common word set.\n",
    "# Each value is the count of the times the word appears in each sentence.\n",
    "def bow_features(sentences, common_words):\n",
    "    \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0]\n",
    "    df['text_source'] = sentences[1]\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df\n",
    "\n",
    "# Set up the bags.\n",
    "blakewords = bag_of_words(blake_doc)\n",
    "paradisewords = bag_of_words(paradise_doc)\n",
    "\n",
    "# Combine bags to create a set of unique words.\n",
    "common_words = set(blakewords + paradisewords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 0\n",
      "Processing row 50\n",
      "Processing row 100\n",
      "Processing row 150\n",
      "Processing row 200\n",
      "Processing row 250\n",
      "Processing row 300\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audacious</th>\n",
       "      <th>music</th>\n",
       "      <th>glory</th>\n",
       "      <th>roll</th>\n",
       "      <th>seed</th>\n",
       "      <th>realm</th>\n",
       "      <th>perfidious</th>\n",
       "      <th>pain</th>\n",
       "      <th>afric</th>\n",
       "      <th>stream</th>\n",
       "      <th>...</th>\n",
       "      <th>aim</th>\n",
       "      <th>altar</th>\n",
       "      <th>damp</th>\n",
       "      <th>reed</th>\n",
       "      <th>orders</th>\n",
       "      <th>furnace</th>\n",
       "      <th>servile</th>\n",
       "      <th>reiterated</th>\n",
       "      <th>text_sentence</th>\n",
       "      <th>text_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Of, Man, 's, first, disobedience, ,, and, the...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(And, chiefly, thou, ,, O, Spirit, ,, that, do...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Say, first, for, Heaven, hides, nothing, from...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Who, first, seduced, them, to, that, foul, re...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(Th, ', infernal, Serpent, ;, he, it, was, who...</td>\n",
       "      <td>Milton</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2081 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  audacious music glory roll seed realm perfidious pain afric stream  \\\n",
       "0         0     0     0    0    1     0          0    0     0      0   \n",
       "1         0     0     0    0    0     0          0    0     0      0   \n",
       "2         0     0     0    0    0     0          0    0     0      0   \n",
       "3         0     0     0    0    0     0          0    0     0      0   \n",
       "4         0     0     1    0    0     0          0    0     0      0   \n",
       "\n",
       "      ...     aim altar damp reed orders furnace servile reiterated  \\\n",
       "0     ...       0     0    0    0      0       0       0          0   \n",
       "1     ...       0     0    0    0      0       0       0          0   \n",
       "2     ...       0     0    0    0      0       0       0          0   \n",
       "3     ...       0     0    0    0      0       0       0          0   \n",
       "4     ...       1     0    0    0      0       0       0          0   \n",
       "\n",
       "                                       text_sentence text_source  \n",
       "0  (Of, Man, 's, first, disobedience, ,, and, the...      Milton  \n",
       "1  (And, chiefly, thou, ,, O, Spirit, ,, that, do...      Milton  \n",
       "2  (Say, first, for, Heaven, hides, nothing, from...      Milton  \n",
       "3  (Who, first, seduced, them, to, that, foul, re...      Milton  \n",
       "4  (Th, ', infernal, Serpent, ;, he, it, was, who...      Milton  \n",
       "\n",
       "[5 rows x 2081 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create our data frame with features. This can take a while to run.\n",
    "word_counts = bow_features(sentences, common_words)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "Y = word_counts['text_source']\n",
    "X = np.array(word_counts.drop(['text_sentence','text_source'], 1))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    Y,\n",
    "                                                    test_size=0.4,\n",
    "                                                    random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.0\n",
      "\n",
      "Test set score: 0.9692307692307692\n",
      "\n",
      "Cross Validation:\n",
      "    0.92 (+/- 0.00)\n",
      "[0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692]\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', rfc.score(X_train, y_train))\n",
    "print('\\nTest set score:', rfc.score(X_test, y_test))\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, random_state=1337)\n",
    "\n",
    "score = cross_val_score(rfc, X_test, y_test, cv=split, scoring='accuracy')\n",
    "print(\"\\nCross Validation:\\n    %0.2f (+/- %0.2f)\" % (score.mean(), score.std()))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.0\n",
      "\n",
      "Test set score: 0.9461538461538461\n",
      "\n",
      "Cross Validation:\n",
      "    0.92 (+/- 0.00)\n",
      "[0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.92307692 0.92307692]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(penalty='l2') # No need to specify l2 as it's the default. But we put it for demonstration.\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', lr.score(X_train, y_train))\n",
    "print('\\nTest set score:', lr.score(X_test, y_test))\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, random_state=1337)\n",
    "\n",
    "score = cross_val_score(lr, X_test, y_test, cv=split, scoring='accuracy')\n",
    "print(\"\\nCross Validation:\\n    %0.2f (+/- %0.2f)\" % (score.mean(), score.std()))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 1.0\n",
      "\n",
      "Test set score: 0.9384615384615385\n",
      "\n",
      "Cross Validation:\n",
      "    0.91 (+/- 0.03)\n",
      "[0.92307692 0.92307692 0.92307692 0.92307692 0.92307692 0.92307692\n",
      " 0.92307692 0.92307692 0.84615385 0.84615385]\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print('Training set score:', clf.score(X_train, y_train))\n",
    "print('\\nTest set score:', clf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=10, random_state=1337)\n",
    "\n",
    "score = cross_val_score(clf, X_test, y_test, cv=split, scoring='accuracy')\n",
    "print(\"\\nCross Validation:\\n    %0.2f (+/- %0.2f)\" % (score.mean(), score.std()))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the nature of TF-IDF and Bag of Words having some overlapping representation of word frequency, we expect that the performance would be similar between feature sets. On average, we observe better performance for TF-IDF across mutliple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
