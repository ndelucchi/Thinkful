{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "toxic_tensorflow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKHWnEV_O4W4",
        "colab_type": "text"
      },
      "source": [
        "**[GET DATA HERE](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/data)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMW7AWlMLv0m",
        "colab_type": "code",
        "outputId": "e18ab47f-bb4d-4be6-cba2-4a45cbe21749",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "from imblearn.combine import SMOTETomek\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn import neighbors, ensemble,tree\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedShuffleSplit"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsYgr6vgL3Y0",
        "colab_type": "code",
        "outputId": "ef7f2b5d-b709-4adc-9d28-bc6c52389a01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6gyaGjaL3b-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swyQBvo0L3fh",
        "colab_type": "code",
        "outputId": "96af605c-37e1-4b46-d327-bb948bc4496c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#import test.csv\n",
        "toxic = pd.read_csv('train.csv')\n",
        "\n",
        "#feature engineering\n",
        "toxic['toxic_total'] = (toxic['toxic'] + toxic['severe_toxic'] +\n",
        "                        toxic['obscene'] + toxic['threat'] + \n",
        "                        toxic['insult'] + toxic['identity_hate'])\n",
        "toxic['toxic_bool'] = np.where((toxic['toxic'] + toxic['severe_toxic'] +\n",
        "                        toxic['obscene'] + toxic['threat'] + \n",
        "                        toxic['insult'] + toxic['identity_hate'])>0,1,0)\n",
        "toxic.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>toxic_total</th>\n",
              "      <th>toxic_bool</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... toxic_bool\n",
              "0  0000997932d777bf  ...          0\n",
              "1  000103f0d9cfb60f  ...          0\n",
              "2  000113f07ec002fd  ...          0\n",
              "3  0001b41b1c6bb37e  ...          0\n",
              "4  0001d958c54c6e35  ...          0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mktS_I3RL3ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the features and the outcome.\n",
        "X = toxic['comment_text']\n",
        "y = toxic['toxic']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,\n",
        "                                                    y, \n",
        "                                                    test_size=0.25, \n",
        "                                                    random_state=42,\n",
        "                                                    stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiPavs_Cx7yn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "818942b2-ba5a-4f01-8ff7-75a0542c7f9a"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37665     1\n",
              "124594    0\n",
              "132186    0\n",
              "149552    0\n",
              "76104     0\n",
              "Name: toxic, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXEK8DeJL3l0",
        "colab_type": "code",
        "outputId": "03acb510-4c1b-426e-ce2f-a313bba7612f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "start_time = time.time()\n",
        "\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_df=0.5, # drop words that occur in more than half the paragraphs\n",
        "                             min_df=3, # only use words that appear at least three times\n",
        "                             stop_words='english', \n",
        "                             lowercase=True, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
        "                             use_idf=True,#we definitely want to use inverse document frequencies in our weighting\n",
        "                             norm=u'l2', #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
        "                             smooth_idf=True #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
        "                            )\n",
        "\n",
        "#Applying the vectorizer\n",
        "toxic_tfidf_train = vectorizer.fit_transform(X_train)\n",
        "toxic_tfidf_test = vectorizer.transform(X_test)\n",
        "print(\"vectorizer complete\")\n",
        "\n",
        "#Reshapes the vectorizer output into something people can read\n",
        "X_train_tfidf_csr = toxic_tfidf_train.tocsr()\n",
        "X_test_tfidf_csr = toxic_tfidf_test.tocsr()\n",
        "print('tocsr complete')\n",
        "\n",
        "#number of sentences\n",
        "n = X_train_tfidf_csr.shape[0]\n",
        "#A list of dictionaries, one per sentence\n",
        "tfidf_bysent = [{} for _ in range(0,n)]\n",
        "#List of features\n",
        "terms = vectorizer.get_feature_names()\n",
        "#for each sentence, lists the feature words and their tf-idf scores\n",
        "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
        "    tfidf_bysent[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
        "print('tf-idf complete')\n",
        "    \n",
        "# Normalize the data.\n",
        "X_train_norm = normalize(X_train_tfidf_csr)\n",
        "X_test_norm = normalize(X_test_tfidf_csr)\n",
        "print('normalization complete')\n",
        "\n",
        "# Convert y to categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "print('to_categorical complete')\n",
        "t= round((time.time() - start_time),4)\n",
        "print(\"\\n -- %s seconds for results--\" % t)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vectorizer complete\n",
            "tocsr complete\n",
            "tf-idf complete\n",
            "normalization complete\n",
            "to_categorical complete\n",
            "\n",
            " -- 57.0011 seconds for results--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDiTd_43yiZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "f395b2e0-c1dc-42b5-a747-74c1cc0b720a"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1FvIxjhMSTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#pickle.dump(vectorizer,open('tf_idf_vectorize.sav','wb'))\n",
        "#vectorizer = pickle.load(open('tf_idf_vectorize.sav','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14MySo6bMSq3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train_vec = vectorizer.transform(X_train)\n",
        "#X_test_vec = vectorizer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxO1yELHMSvX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "37813f3f-7a5a-4e8e-f234-87347f2712e7"
      },
      "source": [
        "start_time = time.time()\n",
        "smt = SMOTETomek(random_state=42)\n",
        "#class balancing\n",
        "#only perform on the training set, this reduces bias in fitting the model.\n",
        "X_res, y_res = smt.fit_resample(X_train_norm, y_train)\n",
        "#print(pd.Series(y_res).value_counts())\n",
        "\n",
        "t= round((time.time() - start_time),4)\n",
        "print(\"\\n -- %s seconds for results--\" % t)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " -- 1401.6027 seconds for results--\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DME002rMS1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#save transformed and class-balanced training set\n",
        "#pickle.dump(X_res,open('X_res_n.pickle','wb'))\n",
        "#pickle.dump(y_res,open('y_res_n.pickle','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJBiPCWyMS5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load pickled X_res and y_res\n",
        "X_pro = pickle.load(open('X_res_n.pickle','rb'))\n",
        "y_pro = pickle.load(open('y_res_n.pickle','rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGbttwnlPWLH",
        "colab_type": "code",
        "outputId": "9ad113ac-e157-46d7-f938-0ab2d29c8215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_pro.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(216390, 44443)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg6GszOcMS9M",
        "colab_type": "code",
        "outputId": "278b0b35-5261-467f-c0cf-1734056da17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pro.shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(216390, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWy2p5PPMS3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Import various componenets for model building\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.layers import LSTM, Input, TimeDistributed\n",
        "from keras.models import Model\n",
        "from keras.optimizers import RMSprop\n",
        "\n",
        "# Import the backend\n",
        "from keras import backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVt5o9ltaFM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from sklearn.preprocessing import OneHotEncoder\n",
        "#enc = OneHotEncoder()\n",
        "#enc.fit_transform(X_res.toarray())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cyh0RIU8MSze",
        "colab_type": "code",
        "outputId": "daa16be8-8fdf-4a0d-fcc0-1d824c3569f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Initialize the constructor\n",
        "model = Sequential()\n",
        "\n",
        "# Add an input layer \n",
        "model.add(Dense(100, activation='relu', input_dim= X_pro.shape[1] ))\n",
        "\n",
        "# Add a hidden layer \n",
        "model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Add a hidden layer \n",
        "model.add(Dense(100, activation='relu'))\n",
        "\n",
        "# Add an output layer \n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0719 02:39:03.813142 139667886278528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0719 02:39:03.837331 139667886278528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0719 02:39:03.841295 139667886278528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 100)               4444400   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 4,464,802\n",
            "Trainable params: 4,464,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsbzFu_QMStL",
        "colab_type": "code",
        "outputId": "11300528-1d69-4b54-faaf-b59452710946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "model.compile(loss='mse',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "                   \n",
        "model.fit(X_pro, y_pro,epochs=3, batch_size=512, verbose=1,validation_data=(X_test_norm, y_test))\n",
        "score = model.evaluate(X_test_norm, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0719 02:39:20.729770 139667886278528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0719 02:39:20.877304 139667886278528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0719 02:39:20.991807 139667886278528 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 216390 samples, validate on 39893 samples\n",
            "Epoch 1/3\n",
            "216390/216390 [==============================] - 168s 778us/step - loss: 0.0490 - acc: 0.9459 - val_loss: 0.0406 - val_acc: 0.9499\n",
            "Epoch 2/3\n",
            "216390/216390 [==============================] - 170s 788us/step - loss: 0.0079 - acc: 0.9906 - val_loss: 0.0430 - val_acc: 0.9501\n",
            "Epoch 3/3\n",
            "216390/216390 [==============================] - 170s 788us/step - loss: 0.0031 - acc: 0.9966 - val_loss: 0.0451 - val_acc: 0.9471\n",
            "Test loss: 0.04507300149703966\n",
            "Test accuracy: 0.9471335823342342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxJxuwbE83ac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(model,open('tensorflow.sav','wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}