{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Now it's time for another guided example. This time we're going to look at recipes. Specifically we'll use the epicurious dataset, which has a collection of recipes, key terms and ingredients, and their ratings.\n",
    "\n",
    "What we want to see is if we can use the ingredient and keyword list to predict the rating. For someone writing a cookbook this could be really useful information that could help them choose which recipes to include because they're more likely to be enjoyed and therefore make the book more likely to be successful.\n",
    "\n",
    "First let's load the dataset. It's [available on Kaggle](https://www.kaggle.com/hugodarwood/epirecipes). We'll use the csv file here and as pull out column names and some summary statistics for ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('epi_r.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data = raw_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raw_data.rating.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "We learn a few things from this analysis. From a ratings perspective, there are just over 20,000 recipes with an average rating of 3.71. What is interesting is that the 25th percentile is actually above the mean. This means there is likely some kind of outlier population. This makes sense when we think about reviews: some bad recipes may have very few very low reviews.\n",
    "\n",
    "Let's validate the idea a bit further with a histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_data.rating.hist(bins=20)\n",
    "plt.title('Histogram of Recipe Ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "So a few things are shown in this histogram. Firstly there are sharp discontinutities. We don't have continuous data. No recipe has a 3.5 rating, for example. Also we see the anticipated increase at 0.\n",
    "\n",
    "Let's try a naive approach again, this time using SVM Regressor. But first, we'll have to do a bit of data cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count nulls \n",
    "null_count = raw_data.isnull().sum()\n",
    "null_count[null_count>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "What we can see right away is that nutrition information is not available for all goods. Now this would be an interesting data point, but let's focus on ingredients and keywords right now. So we'll actually drop the whole columns for calories, protein, fat, and sodium. We'll come back to nutrition information later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr = SVR()\n",
    "X = raw_data.drop(['rating', 'title', 'calories', 'protein', 'fat', 'sodium'], 1).sample(frac=0.3, replace=True, random_state=1)\n",
    "Y = raw_data.rating.sample(frac=0.3, replace=True, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr.fit(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "__Note that this actually takes quite a while to run, compared to some of the models we've done before. Around 5-7 mins. Be patient.__ It's because of the number of features we have.\n",
    "\n",
    "Let's see what a scatter plot looks like, comparing actuals to predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(Y, svr.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Now that is a pretty useless visualization. This is because of the discontinous nature of our outcome variable. There's too much data for us to really see what's going on here. If you wanted to look at it you could create histograms, here we'll move on to the scores of both our full fit model and with cross validation. Again if you choose to run it again it will take some time, so you probably shouldn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.003978314483867873"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr.score(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.01787926, -0.02916288, -0.02841122, -0.03767394, -0.01735362])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(svr, X, Y, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "Oh dear, so this did seem not to work very well. In fact it is remarkably poor. Now there are many things that we could do here. \n",
    "\n",
    "Firstly the overfit is a problem, even though it was poor in the first place. We could go back and clean up our feature set. There might be some gains to be made by getting rid of the noise.\n",
    "\n",
    "We could also see how removing the nulls but including dietary information performs. Though its a slight change to the question we could still possibly get some improvements there.\n",
    "\n",
    "Lastly, we could take our regression problem and turn it into a classifier. With this number of features and a discontinuous outcome, we might have better luck thinking of this as a classification problem. We could make it simpler still by instead of classifying on each possible value, group reviews to some decided high and low values.\n",
    "\n",
    "__And that is your challenge.__\n",
    "\n",
    "Transform this regression problem into a binary classifier and clean up the feature set. You can choose whether or not to include nutritional information, but try to cut your feature set down to the 30 most valuable features.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "When you've finished that, also take a moment to think about bias. Is there anything in this dataset that makes you think it could be biased, perhaps extremely so?\n",
    "\n",
    "There is. Several things in fact, but most glaringly is that we don't actually have a random sample. It could be, and probably is, that the people more likely to choose some kinds of recipes are more likely to give high reviews.\n",
    "\n",
    "After all, people who eat chocolate _might_ just be happier people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape:    (15864, 678)\n",
      "transformed shape: (15864, 30)\n"
     ]
    }
   ],
   "source": [
    "X = raw_data.drop(['rating', 'title'], 1)\n",
    "X = X.dropna()\n",
    "Y = raw_data.rating\n",
    "Y = Y.dropna()\n",
    "Y = np.where( Y>3 , 1, 0) \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "pca.fit(X)\n",
    "X_pca = pca.transform(X)\n",
    "\n",
    "print(\"original shape:   \", X.shape)\n",
    "print(\"transformed shape:\", X_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.9618003025718608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Score: 0.9651\n",
      "Testing Score: 0.8985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/nickdelucchi/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation Score:  0.8922  +/-  0.0004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "\n",
    "svc.fit(X_pca,Y)\n",
    "\n",
    "print('Accuracy score',svc.score(X_pca, Y))\n",
    "\n",
    "X_train , X_test, y_train, y_test = train_test_split(X_pca, Y, test_size = 0.2, random_state=1)\n",
    "trained = svc.fit(X_train, y_train)\n",
    "print('\\nTraining Score:', round(trained.score(X_train, y_train),4))\n",
    "print('Testing Score:', round(trained.score(X_test, y_test),4))\n",
    "\n",
    "cvs = cross_val_score(svc, X_pca, Y, cv=5)\n",
    "print('Cross validation Score: ', round(cvs.mean(),4), ' +/- ', round(cvs.std(),4) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared is much better than before but CVS is very low but consistent. Model still overfit. Wat?\n",
    "\n",
    "How do you choose when you have ~680 features to choose from? Also, why select only 30 when you can retain all the info in PCA? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
